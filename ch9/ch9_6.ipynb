{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.6.2 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.458 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['抄袭', '得', '那么', '明显', '也', '是', '醉', '了', '！'] 分类 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jieba\n",
    "\n",
    "def load():\n",
    "    arr = ['不知道该说什么, 这么烂的抄袭片也能上映, 我感到很尴尬',\n",
    "       '天呐。一个大写的滑稽。',\n",
    "       '剧情太狗血，演技太浮夸，结局太无语。总体太渣了。这一个半小时废了。',\n",
    "       '画面很美，音乐很好听，主角演的很到位，很值得一看的电影，男主角很帅很帅，赞赞赞',\n",
    "       '超级喜欢的一部爱情影片',\n",
    "       '故事情节吸引人，演员演的也很好，电影里的歌也好听，总之值得一看，看了之后也会很感动的。']\n",
    "    ret = []\n",
    "    for i in arr:\n",
    "        words = jieba.lcut(i) # 将句子切分成词\n",
    "        ret.append(words)\n",
    "    return ret,[0,0,0,1,1,1]\n",
    "\n",
    "def create_vocab(data):\n",
    "    vocab_set = set([])# 使用set集合操作去掉重复出现的词汇\n",
    "    for document in data:\n",
    "        vocab_set = vocab_set | set(document) \n",
    "    return list(vocab_set)\n",
    "\n",
    "def words_to_vec(vocab_list, vocab_set):  # 将句转换成词表格式\n",
    "    ret = np.zeros(len(vocab_list)) # 创建数据表中的一行，并置初值为0（不存在）\n",
    "    for word in vocab_set:\n",
    "        if word in vocab_list:\n",
    "            ret[vocab_list.index(word)] = 1  # 若该词在本句中出现，则设置为1\n",
    "    return ret\n",
    "\n",
    "def train(X, y):\n",
    "    rows = X.shape[0]\n",
    "    cols = X.shape[1]\n",
    "    percent = sum(y)/float(rows) # 正例占比\n",
    "    p0_arr = np.ones(cols) # 设置初值为1，后作为分子\n",
    "    p1_arr = np.ones(cols)\n",
    "    p0_count = 2.0 # 设初值为2，后作为分母\n",
    "    p1_count = 2.0\n",
    "    for i in range(rows): # 按每句遍历\n",
    "        if y[i] == 1:\n",
    "            p1_arr += X[i] # 数组按每个值相加\n",
    "            p1_count += sum(X[i]) # 句子所有词个数相加(只计词汇表中词)\n",
    "        else:\n",
    "            p0_arr += X[i]\n",
    "            p0_count += sum(X[i])\n",
    "    p1_vec = np.log(p1_arr/p1_count) # 正例时，每个词出现概率\n",
    "    p0_vec = np.log(p0_arr/p0_count)\n",
    "    return p0_vec, p1_vec, percent\n",
    "\n",
    "def predict(X, p0_vec, p1_vec, percent):\n",
    "    p1 = sum(X * p1_vec) + np.log(percent) # 为1的概率\n",
    "    p0 = sum(X * p0_vec) + np.log(1.0 - percent) #为0的概率\n",
    "    if p1 > p0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sentences,y = load()\n",
    "    vocab_list = create_vocab(sentences)\n",
    "    X=[]\n",
    "    for sentence in sentences:\n",
    "        X.append(words_to_vec(vocab_list, sentence))\n",
    "    p0_vec, p1_vec, percent = train(np.array(X), np.array(y))\n",
    "    test = jieba.lcut('抄袭得那么明显也是醉了！')\n",
    "    test_X = np.array(words_to_vec(vocab_list, test))\n",
    "    print(test,'分类',predict(test_X, p0_vec, p1_vec, percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.6.3 贝叶斯网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此程序段需要在 Python 2系统中运行\n",
    "\n",
    "from bayesian.bbn import build_bbn\n",
    "\n",
    "def f_prize_door(prize_door):\n",
    "    return 0.33333333\n",
    "def f_guest_door(guest_door):\n",
    "    return 0.33333333\n",
    "def f_monty_door(prize_door, guest_door, monty_door):\n",
    "    if prize_door == guest_door:  # 参赛者猜对了\n",
    "        if prize_door == monty_door:\n",
    "            return 0     # Monty不会打开有车的那扇门，不可能发生\n",
    "        else:\n",
    "            return 0.5   # Monty会打开其它两扇门，二选一\n",
    "    elif prize_door == monty_door:\n",
    "        return 0         #  Monty不会打开有车的那扇门，不可能发生\n",
    "    elif guest_door == monty_door:\n",
    "        return 0         # 门已经由参赛者选定，不可能发生\n",
    "    else:\n",
    "        return 1    # Monty打开另一扇有羊的门\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    g = build_bbn(f_prize_door, f_guest_door, f_monty_door,\n",
    "        domains=dict(\n",
    "            prize_door=['A', 'B', 'C'],\n",
    "            guest_door=['A', 'B', 'C'],\n",
    "            monty_door=['A', 'B', 'C']))\n",
    "    g.q(guest_door='A', monty_door='B') # 假设参赛者打开门A，Monty打开门B"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
