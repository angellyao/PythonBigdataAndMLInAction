{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意: data中数据文件只包括少量数据，用于示例，请从天池下载完整数据后训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入头文件\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings \n",
    "import re\n",
    "import tools # 工具实现在tools.py文件中\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读训练数据\n",
    "data = pd.read_csv('data/weibo_train_data.txt',sep='\\t',header=None)\n",
    "data = tools.prepare(data)\n",
    "data = tools.add_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切分训练集和验证集\n",
    "train,val = train_test_split(data, test_size=0.2, random_state=0)\n",
    "val = val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    f    c    l\n",
      "uid                                            \n",
      "000c663a24a2f91f4ba156fcd4f8b9f2  0.0  0.0  0.0\n",
      "001e00fddab72bf7e6be3455e199904a  0.0  0.0  0.0\n",
      "00629276bf87e3b0ffb8930d658d21bd  0.0  0.0  0.0\n",
      "00c8986de0a9e2e8de08d9b7a315c690  0.0  0.0  0.0\n",
      "00e77096cebd1a5c5e88b2603429866c  0.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "# 按用户分组\n",
    "if True:\n",
    "    grp = train.groupby('uid')\n",
    "    user_data = pd.DataFrame()\n",
    "    user_data['f'] = grp['f'].mean()\n",
    "    user_data['c'] = grp['c'].mean()\n",
    "    user_data['l'] = grp['l'].mean()\n",
    "else:\n",
    "    user_data = pd.read_csv(\"train_user.csv\")\n",
    "user_data_2 = user_data.rename(columns={'l':'avg_l','c':'avg_c','f':'avg_f'})\n",
    "print(user_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "import xgboost as xgb\n",
    "\n",
    "def testme_f(preds,dtrain):\n",
    "    labels=pd.Series(dtrain.get_label())\n",
    "    tmp = pd.DataFrame()\n",
    "    d = ((preds - labels)/(labels + 5.0)).apply(lambda x: abs(x))\n",
    "    count_i = labels\n",
    "    precision = 1 - d\n",
    "    sign = np.sign(precision - 0.8).apply(lambda x: 0 if x == -1 else 1)\n",
    "    count_i[count_i > 50] = 50\n",
    "    count_1 = sum((count_i + 1) * sign)\n",
    "    count_2 = sum(count_i + 1)\n",
    "    return 'testme', 1 - count_1/count_2\n",
    "\n",
    "def testme_lc(preds,dtrain):\n",
    "    labels=pd.Series(dtrain.get_label())\n",
    "    tmp = pd.DataFrame()\n",
    "    d = ((preds - labels)/(labels + 3.0)).apply(lambda x: abs(x))\n",
    "    count_i = labels\n",
    "    precision = 1 - d\n",
    "    sign = np.sign(precision - 0.8).apply(lambda x: 0 if x == -1 else 1)\n",
    "    count_i[count_i > 25] = 25\n",
    "    count_1 = sum((count_i + 1) * sign)\n",
    "    count_2 = sum(count_i + 1)\n",
    "    return 'testme', 1 - count_1/count_2\n",
    "\n",
    "def calc(grp1, grp2, features, key, params, feval):\n",
    "    train_X = grp1[features]\n",
    "    train_Y = grp1[key]\n",
    "    val_X = grp2[features]\n",
    "    val_Y = grp2[key]\n",
    "    dtrain = xgb.DMatrix(train_X, train_Y)\n",
    "    dval = xgb.DMatrix(val_X, val_Y)\n",
    "    watchlist  = [(dtrain,'train'),(dval,'val')]\n",
    "    model = xgb.train(params,dtrain, evals=watchlist, feval=feval, \n",
    "                      num_boost_round=200, early_stopping_rounds=10)\n",
    "    model.save_model('model_'+key)\n",
    "    dic = model.get_fscore()\n",
    "    dic2= sorted(dic.items(), key=lambda d:d[1], reverse = True)\n",
    "    print(\"feature importance\", dic2)\n",
    "    return model\n",
    "\n",
    "params={\n",
    "    'max_depth':7,\n",
    "    'subsample':0.7,\n",
    "    'eta': 0.05,\n",
    "    'seed':5,\n",
    "    'objective':'reg:linear'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "986\n",
      "16032\n",
      "['红包', '分享', '一个', '打车', '数据', '什么', '可以', '技术', '自己', '一起', '我们', '联网', '安全', '就是', '互联', '网络', '开发', '没有', '互联网', '现金', '今天', '试试', '这个', '服务', '学习', '手机', '中国', '信息', '问题', '代金', '代金券', '已经', '来试', '快来', '用户', '下载', '系统', '智能', '生活', '文章', '公司', '应用', '一种', '第一', '开始', '视频', '发出', '试手', '不要', '推荐', '看看', '市场', '手气', '使用', '如何', '刚刚', '正在', '真的', '企业', '起来', '工作', '大家', '现在', '管理', '发红包', '产品', '还是', '发红', '科技', '个人', '快乐', '时候', '通过', '这里', '移动', '项目', '支付', '博客', '如果', '知识', '更多', '行业', '觉得', '客户', '时间', '活动', '不是', '程序', '阅读', '知道', '能力', '幸福', '世界', '城市', '礼包', '好运', '一次', '你们', '关心', '体验', '网站', '设备', '发布', '内容', '进行', '免费', '北京', '喜欢', '大学', '小伙', '抢到', '支付宝', '平台', '需要', '来自', '感觉', '音乐', '代码', '运动', '看到', '伙伴', '中心', '文件', '怎么', '机器', '不能', '以及', '设计', '哈哈', '客户端', '支持', '更新', '计算', '投资', '空间', '链接', '希望', '成为', '基础', '出来', '不错', '学生', '抢红包', '有人', '功能', '硬件', '提供', '环境', '还有', '实现', '钱包', '时代', '每天', '这些', '专业', '创新', '资源', '很多', '小伙伴', '电脑', '因为', '最新', '错过', '小财神', '小财', '情人', '发现', '在线', '他们', '只是', '发展', '医疗', '软件', '土豪', '商务', '健康', '这么', '财神', '升级', '论坛', '东西', '架构', '挣钱', '分析', '最近', '方式', '来看', '运营', '超大', '应该', '一下', '这样', '有钱', '介绍', '所有', '那么', '开发者', '算法', '扇贝', '人生', '方法', '投票', '日本', '发表', '一直', '获得', '单词', '大数', '开启', '大红', '前端', '作为', '一天', '不知', '一样', '重要', '苹果', '关于', '收购', '基于', '粉丝', '消息', '克拉', '注册', '网络安全', '今日', '天天', '非常', '专家', '工业', '朋友', '会员', '工程', '测试', '超级', '只有', '百度', '小时', '创业', '简单', '国内', '下来', '新闻', '状态', '回家', '真正', '推出', '可能', '大量', '文档', '一点', '工程师', '研究', '点击', '其实', '天都', '网上', '继续', '加油', '切换', '真是', '不会', '处理', '网易', '深圳', '地址', '订单', '抓狂', '那些', '服务器', '华为', '想要', '别人', '信息安全', '大红包', '包括', '了解', '工具', '福气', '日报', '份额', '机会', '加入', '任何', '对于', '图片', '博客园', '教育', '国家', '新浪', '务器', '突然', '模式', '参与', '博文', '查看', '情况', '印象', '负责', '分布', '存储', '但是', '漂亮', '头条', '孩子', '本文', '那个', '拜拜', '曝光', '决定', '电子', '速度', '笔记', '学院', '分布式', '一张', '官方', '声音', '计划', '讨论', '员工', '只要', '风雨', '一条', '国美', '攻击', '先来', '市场份额', '解决', '游戏', '主要', '医生', '发起', '看吧', '怎样', '全部', '围观', '自然', '模型', '打卡', '文库', '有效', '失败', '布式', '未来', '阿里', '部分', '京东', '参加', '情人节', '理解', '要求', '几个', '直接', '评论', '害羞', '越来越', '详细', '据库', '生物', '购物', '小学', '数据库', '或者', '详情', '挖掘', '明星', '小米', '为什么', '电视', '漏洞', '开心', '数据中心', '变成', '语言', '封面', '为何', '就此', '多数', '提出', '页面', '消费', '今年', '接下', '完成', '各种', '认为', '事情', '大奖', '关键', '一年', '过程', '不过', '公布', '春晚', '专车', '必须', '而且', '目前', '东方', '领取', '保护', '大多', '现场', '稳居', '看完', '所以', '开源', '随手', '大多数', '周年', '提升', '面试', '挑战', '生命', '亿元', '恋人', '第三', '腾讯', '然后', '图标', '动画', '自由', '越来', '努力', '记者', '这种', '礼物', '千万', '智慧', '能够', '心情', '之前', '到底', '邀请', '提高', '正式', '整个', '全文', '无论', '关系', '业务', '天变', '熊猫', '棒棒', '选项', '同行', '容易', '职业', '天下', '日前', '哪些', '日头', '旅行', '贴心', '自动', '以下', '金融', '社区', '销售', '系列', '实施', '课程', '欢庆', '照片', '话题', '亚马逊', '以前', '主题', '亚马', '达到', '头彩', '即使', '目的', '加密', '品牌', '特别', '创建', '连接', '团队', '当然', '有点', '对话', '啊啊啊', '上市', '表态', '一些', '一场', '女神', '老师', '核心', '定义', '大会', '不好', '为了', '控制', '有限', '回答', '地图', '选择', '经验', '人员', '宇宙', '公交', '微软', '广告', '依然', '按钮', '璀璨', '大吉', '讨厌', '思想', '经典', '操作', '两个', '明天', '全新', '专注', '偷笑', '我国', '高级', '男人', '成熟', '方案', '价值', '事件', '成功', '生病', '文化', '办公', '图图', '源码', '模板', '原因', '三年', '总有一天', '抢点']\n"
     ]
    }
   ],
   "source": [
    "# 提取关键词\n",
    "import jieba\n",
    "\n",
    "# tmp=data.sample(n = 100000) # adjust\n",
    "tmp = data.sample(n = 1000)\n",
    "arr = tmp['content'].unique()\n",
    "print(len(arr))\n",
    "arr_all = []\n",
    "for i in arr:\n",
    "    arr = jieba.lcut(i, cut_all=True)\n",
    "    arr_zh = [i for i in arr if len(re.findall(r\"^[#\\+a-z0-9A-Z\\\\-_]+$\",i,re.M)) == 0 and len(i) > 1]\n",
    "    arr_all.extend(arr_zh)\n",
    "print(len(arr_all))\n",
    "\n",
    "result = pd.value_counts(arr_all)\n",
    "arr_word = []\n",
    "for key,value in result.items():\n",
    "    if value > 5:\n",
    "        arr_word.append(key)\n",
    "print(arr_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537\n",
      "1 分享 [3.082848305651958e-05, 16.245960502693, 557] 1\n",
      "54 如何 [0.00520579922219767, 23.354545454545455, 110] 2\n",
      "59 起来 [8.027846753915509e-08, 43.739583333333336, 96] 3\n",
      "61 大家 [8.875207952819432e-16, 55.70634920634921, 126] 4\n",
      "89 知道 [0.03718461527945237, 18.256637168141594, 113] 5\n",
      "102 发布 [0.014234816405484923, 22.921348314606742, 89] 6\n",
      "109 小伙 [2.4263845761329027e-38, 112.58108108108108, 74] 7\n",
      "113 需要 [7.123769961612894e-20, 72.07446808510639, 94] 8\n",
      "120 伙伴 [2.1299206990320807e-36, 106.92307692307692, 78] 9\n",
      "158 小伙伴 [3.906941480410842e-43, 126.22727272727273, 66] 10\n",
      "161 最新 [0.02284157318557919, 31.0, 38] 11\n",
      "172 软件 [5.362786164083642e-09, 49.95294117647059, 85] 12\n",
      "196 开发者 [0.007818458014427756, 38.935483870967744, 31] 13\n",
      "200 方法 [2.3215041709751946e-07, 62.90243902439025, 41] 14\n",
      "213 不知 [0.011825257223198257, 26.432835820895523, 67] 15\n",
      "245 真正 [0.0020993951143830785, 58.588235294117645, 17] 16\n",
      "277 工具 [0.027052104617776296, 28.363636363636363, 44] 17\n",
      "330 主要 [0.010142145345259306, 36.72727272727273, 33] 18\n",
      "347 京东 [0.00030655027551569045, 80.25, 12] 19\n",
      "363 或者 [0.0027797924025507632, 42.06060606060606, 33] 20\n",
      "417 第三 [0.010867768886215332, 42.041666666666664, 24] 21\n",
      "435 提高 [0.0001324180997856552, 62.26086956521739, 23] 22\n",
      "468 主题 [0.031213044312873698, 33.275862068965516, 29] 23\n",
      "475 品牌 [0.009629264104601394, 42.666666666666664, 24] 24\n",
      "533 原因 [0.0013804773637528874, 60.76470588235294, 17] 25\n",
      "537\n",
      "0 红包 [0.03983535227032345, 0.10943396226415095, 265] 1\n",
      "23 服务 [0.0023059077341255753, 3.5042735042735043, 117] 2\n",
      "48 不要 [0.04214492355772638, 3.4545454545454546, 55] 3\n",
      "51 市场 [0.0018965856962079458, 4.2898550724637685, 69] 4\n",
      "61 大家 [2.0254369307012678e-10, 5.873015873015873, 126] 5\n",
      "62 现在 [0.034395797082993965, 2.828828828828829, 111] 6\n",
      "73 这里 [2.1965600664623703e-06, 5.5875, 80] 7\n",
      "81 行业 [0.01633267937842381, 3.824561403508772, 57] 8\n",
      "84 时间 [0.00019997434478324582, 4.128440366972477, 109] 9\n",
      "109 小伙 [1.3577317000741363e-10, 7.405405405405405, 74] 10\n",
      "113 需要 [3.17285949588618e-07, 5.5638297872340425, 94] 11\n",
      "120 伙伴 [7.621290380614714e-10, 6.987179487179487, 78] 12\n",
      "127 设计 [0.0063727102101644685, 4.135593220338983, 59] 13\n",
      "143 有人 [0.0008325542570487567, 5.6, 40] 14\n",
      "158 小伙伴 [7.820859556397194e-12, 8.212121212121213, 66] 15\n",
      "159 电脑 [0.00597760628083728, 4.6, 45] 16\n",
      "161 最新 [0.01669932582864883, 4.421052631578948, 38] 17\n",
      "172 软件 [7.806189999287116e-05, 4.741176470588235, 85] 18\n",
      "190 一下 [4.643895248377202e-09, 7.296875, 64] 19\n",
      "196 开发者 [0.007111534773862411, 5.225806451612903, 31] 20\n",
      "230 朋友 [0.0004724186213870215, 5.188679245283019, 53] 21\n",
      "245 真正 [0.03248939762843195, 5.529411764705882, 17] 22\n",
      "282 加入 [0.004303435187957926, 5.620689655172414, 29] 23\n",
      "312 笔记 [0.04915714617396536, 4.285714285714286, 28] 24\n",
      "313 学院 [0.03228149180515974, 4.2, 35] 25\n",
      "330 主要 [0.0038241065194161293, 5.393939393939394, 33] 26\n",
      "347 京东 [0.0023015276412260526, 8.583333333333334, 12] 27\n",
      "354 评论 [2.4721724271458692e-17, 13.935483870967742, 31] 28\n",
      "363 或者 [0.0002969450081590564, 6.484848484848484, 33] 29\n",
      "412 面试 [3.559774036603101e-05, 8.95, 20] 30\n",
      "417 第三 [0.03660938495845609, 4.75, 24] 31\n",
      "426 这种 [0.0012038415975608987, 5.357142857142857, 42] 32\n",
      "435 提高 [5.811257090253419e-05, 8.26086956521739, 23] 33\n",
      "475 品牌 [0.010776338775096317, 5.541666666666667, 24] 34\n",
      "505 广告 [0.0011466596357428626, 7.0, 22] 35\n",
      "533 原因 [0.0022284814430337295, 7.411764705882353, 17] 36\n",
      "537\n",
      "1 分享 [0.020220585059575014, 5.206463195691203, 557] 1\n",
      "54 如何 [0.047858819751073624, 8.2, 110] 2\n",
      "59 起来 [1.7599706970699598e-06, 17.645833333333332, 96] 3\n",
      "61 大家 [1.5901278388365864e-13, 22.904761904761905, 126] 4\n",
      "73 这里 [0.000532265286220342, 14.5, 80] 5\n",
      "84 时间 [0.0003989935730273806, 12.944954128440367, 109] 6\n",
      "109 小伙 [2.7844333297695963e-30, 44.08108108108108, 74] 7\n",
      "113 需要 [3.0139406330325305e-15, 27.893617021276597, 94] 8\n",
      "120 伙伴 [1.0339617216310323e-28, 41.85897435897436, 78] 9\n",
      "127 设计 [0.03918612931967754, 10.76271186440678, 59] 10\n",
      "158 小伙伴 [4.615751624287504e-34, 49.378787878787875, 66] 11\n",
      "172 软件 [8.578807355542199e-07, 19.11764705882353, 85] 12\n",
      "190 一下 [7.341133498011931e-06, 20.0, 64] 13\n",
      "200 方法 [4.384866620781785e-05, 22.51219512195122, 41] 14\n",
      "213 不知 [0.028707570119816516, 10.716417910447761, 67] 15\n",
      "354 评论 [7.334368071156692e-11, 39.38709677419355, 31] 16\n"
     ]
    }
   ],
   "source": [
    "# 从文字中提取特征\n",
    "from scipy import stats\n",
    "\n",
    "def get_dic(arr_word, dst, count, data):\n",
    "    print(len(arr_word))\n",
    "    dic_key = {}\n",
    "    for idx,i in enumerate(arr_word):\n",
    "        df1 = data[data['content'].str.contains(i)==False]\n",
    "        df2 = data[data['content'].str.contains(i)==True]\n",
    "        ret2 = stats.levene(df1[dst], df2[dst])\n",
    "        if ret2[1] < 0.05:\n",
    "            dic_key[i] = [ret2[1], df2[dst].mean(), len(df2)]\n",
    "            print(idx, i, dic_key[i], len(dic_key))\n",
    "            if len(dic_key) > count:\n",
    "                break\n",
    "    return dic_key\n",
    "\n",
    "dic_key_f = get_dic(arr_word, 'f', 100, data[:100000])\n",
    "dic_key_c = get_dic(arr_word, 'c', 50, data[:100000])\n",
    "dic_key_l = get_dic(arr_word, 'l', 100, data[:100000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.merge(val, user_data_2, on='uid', how='left')\n",
    "train = pd.merge(train, user_data_2, on='uid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:55:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\ttrain-rmse:79.1155\tval-rmse:14.868\ttrain-testme:0.618992\tval-testme:0.612693\n",
      "Multiple eval metrics have been passed: 'val-testme' will be used for early stopping.\n",
      "\n",
      "Will train until val-testme hasn't improved in 10 rounds.\n",
      "[1]\ttrain-rmse:78.3617\tval-rmse:15.1642\ttrain-testme:0.610059\tval-testme:0.610252\n",
      "[2]\ttrain-rmse:76.394\tval-rmse:16.1338\ttrain-testme:0.606564\tval-testme:0.592352\n",
      "[3]\ttrain-rmse:74.0633\tval-rmse:18.3971\ttrain-testme:0.601709\tval-testme:0.594793\n",
      "[4]\ttrain-rmse:71.9015\tval-rmse:19.9814\ttrain-testme:0.596271\tval-testme:0.593979\n",
      "[5]\ttrain-rmse:69.7289\tval-rmse:22.7618\ttrain-testme:0.596854\tval-testme:0.586249\n",
      "[6]\ttrain-rmse:67.65\tval-rmse:25.7422\ttrain-testme:0.596757\tval-testme:0.593572\n",
      "[7]\ttrain-rmse:67.0117\tval-rmse:26.3773\ttrain-testme:0.588795\tval-testme:0.58991\n",
      "[8]\ttrain-rmse:65.1006\tval-rmse:29.3537\ttrain-testme:0.583261\tval-testme:0.586249\n",
      "[9]\ttrain-rmse:63.1097\tval-rmse:31.1847\ttrain-testme:0.576075\tval-testme:0.58869\n",
      "[10]\ttrain-rmse:61.4073\tval-rmse:34.062\ttrain-testme:0.572968\tval-testme:0.593572\n",
      "[11]\ttrain-rmse:60.9899\tval-rmse:34.1126\ttrain-testme:0.565395\tval-testme:0.593979\n",
      "[12]\ttrain-rmse:59.3864\tval-rmse:35.7723\ttrain-testme:0.562191\tval-testme:0.594793\n",
      "[13]\ttrain-rmse:58.0847\tval-rmse:35.6377\ttrain-testme:0.55384\tval-testme:0.576892\n",
      "[14]\ttrain-rmse:57.8564\tval-rmse:35.8904\ttrain-testme:0.545781\tval-testme:0.576892\n",
      "[15]\ttrain-rmse:56.5783\tval-rmse:38.1764\ttrain-testme:0.540441\tval-testme:0.576892\n",
      "[16]\ttrain-rmse:55.8609\tval-rmse:38.994\ttrain-testme:0.540732\tval-testme:0.577299\n",
      "[17]\ttrain-rmse:55.5705\tval-rmse:39.2914\ttrain-testme:0.540441\tval-testme:0.577299\n",
      "[18]\ttrain-rmse:55.3433\tval-rmse:39.5949\ttrain-testme:0.522672\tval-testme:0.579333\n",
      "[19]\ttrain-rmse:53.9684\tval-rmse:41.272\ttrain-testme:0.516652\tval-testme:0.574044\n",
      "[20]\ttrain-rmse:52.7668\tval-rmse:41.1118\ttrain-testme:0.511894\tval-testme:0.580146\n",
      "[21]\ttrain-rmse:52.7186\tval-rmse:40.929\ttrain-testme:0.50704\tval-testme:0.594386\n",
      "[22]\ttrain-rmse:51.325\tval-rmse:42.5067\ttrain-testme:0.506554\tval-testme:0.598454\n",
      "[23]\ttrain-rmse:50.6338\tval-rmse:43.5767\ttrain-testme:0.493252\tval-testme:0.602522\n",
      "[24]\ttrain-rmse:49.4138\tval-rmse:46.1869\ttrain-testme:0.480629\tval-testme:0.602522\n",
      "[25]\ttrain-rmse:48.2334\tval-rmse:47.9088\ttrain-testme:0.470725\tval-testme:0.60415\n",
      "[26]\ttrain-rmse:46.8644\tval-rmse:49.673\ttrain-testme:0.4649\tval-testme:0.60415\n",
      "[27]\ttrain-rmse:46.953\tval-rmse:49.6796\ttrain-testme:0.468492\tval-testme:0.60415\n",
      "[28]\ttrain-rmse:45.825\tval-rmse:51.7067\ttrain-testme:0.458588\tval-testme:0.60415\n",
      "[29]\ttrain-rmse:45.7095\tval-rmse:51.7592\ttrain-testme:0.453539\tval-testme:0.60415\n",
      "Stopping. Best iteration:\n",
      "[19]\ttrain-rmse:53.9684\tval-rmse:41.272\ttrain-testme:0.516652\tval-testme:0.574044\n",
      "\n",
      "feature importance [('avg_f', 319), ('hour', 193), ('weekday', 182), ('avg_l', 96), ('avg_c', 57), ('c_has_link', 36), ('c_has_ex', 34), ('需要', 22), ('c_has_at', 20), ('开发者', 20), ('发布', 18), ('大家', 12), ('品牌', 12), ('起来', 11), ('知道', 9), ('c_has_it', 9), ('c_has_topic', 9), ('主要', 7), ('分享', 7), ('如何', 5), ('伙伴', 3), ('c_has_share', 3), ('c_has_ads', 3), ('提高', 3), ('最新', 2), ('方法', 2), ('小伙', 2), ('软件', 1), ('c_has_video', 1), ('工具', 1), ('第三', 1), ('真正', 1)]\n",
      "[14:55:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\ttrain-rmse:7.27262\tval-rmse:11.726\ttrain-testme:0.51395\tval-testme:0.497686\n",
      "Multiple eval metrics have been passed: 'val-testme' will be used for early stopping.\n",
      "\n",
      "Will train until val-testme hasn't improved in 10 rounds.\n",
      "[1]\ttrain-rmse:7.17866\tval-rmse:11.7208\ttrain-testme:0.478349\tval-testme:0.495116\n",
      "[2]\ttrain-rmse:6.97415\tval-rmse:11.7223\ttrain-testme:0.473551\tval-testme:0.497172\n",
      "[3]\ttrain-rmse:6.7942\tval-rmse:11.7232\ttrain-testme:0.471279\tval-testme:0.496658\n",
      "[4]\ttrain-rmse:6.6045\tval-rmse:11.7329\ttrain-testme:0.465093\tval-testme:0.494087\n",
      "[5]\ttrain-rmse:6.41978\tval-rmse:11.7377\ttrain-testme:0.4608\tval-testme:0.494602\n",
      "[6]\ttrain-rmse:6.2323\tval-rmse:11.7568\ttrain-testme:0.459159\tval-testme:0.484833\n",
      "[7]\ttrain-rmse:6.13974\tval-rmse:11.7594\ttrain-testme:0.452847\tval-testme:0.486375\n",
      "[8]\ttrain-rmse:6.00359\tval-rmse:11.7661\ttrain-testme:0.448428\tval-testme:0.491003\n",
      "[9]\ttrain-rmse:5.84235\tval-rmse:11.7926\ttrain-testme:0.442747\tval-testme:0.491003\n",
      "[10]\ttrain-rmse:5.68944\tval-rmse:11.7985\ttrain-testme:0.44098\tval-testme:0.486889\n",
      "[11]\ttrain-rmse:5.62504\tval-rmse:11.802\ttrain-testme:0.432142\tval-testme:0.487404\n",
      "[12]\ttrain-rmse:5.47434\tval-rmse:11.8191\ttrain-testme:0.417119\tval-testme:0.484319\n",
      "[13]\ttrain-rmse:5.32228\tval-rmse:11.8483\ttrain-testme:0.409039\tval-testme:0.484833\n",
      "[14]\ttrain-rmse:5.28122\tval-rmse:11.8495\ttrain-testme:0.402601\tval-testme:0.488432\n",
      "[15]\ttrain-rmse:5.15822\tval-rmse:11.8822\ttrain-testme:0.396162\tval-testme:0.485861\n",
      "[16]\ttrain-rmse:5.1216\tval-rmse:11.8875\ttrain-testme:0.390733\tval-testme:0.48329\n",
      "[17]\ttrain-rmse:5.06738\tval-rmse:11.89\ttrain-testme:0.385557\tval-testme:0.484833\n",
      "[18]\ttrain-rmse:5.01988\tval-rmse:11.8921\ttrain-testme:0.381139\tval-testme:0.482776\n",
      "[19]\ttrain-rmse:4.8878\tval-rmse:11.9097\ttrain-testme:0.364095\tval-testme:0.484319\n",
      "[20]\ttrain-rmse:4.75731\tval-rmse:11.9432\ttrain-testme:0.346926\tval-testme:0.482776\n",
      "[21]\ttrain-rmse:4.72842\tval-rmse:11.9429\ttrain-testme:0.342507\tval-testme:0.484319\n",
      "[22]\ttrain-rmse:4.62312\tval-rmse:11.9796\ttrain-testme:0.327105\tval-testme:0.484319\n",
      "[23]\ttrain-rmse:4.57499\tval-rmse:11.9855\ttrain-testme:0.317763\tval-testme:0.484319\n",
      "[24]\ttrain-rmse:4.47646\tval-rmse:12.0243\ttrain-testme:0.305138\tval-testme:0.484319\n",
      "[25]\ttrain-rmse:4.36574\tval-rmse:12.0649\ttrain-testme:0.296553\tval-testme:0.488432\n",
      "[26]\ttrain-rmse:4.25801\tval-rmse:12.1016\ttrain-testme:0.279889\tval-testme:0.488432\n",
      "[27]\ttrain-rmse:4.24183\tval-rmse:12.0986\ttrain-testme:0.281404\tval-testme:0.48329\n",
      "[28]\ttrain-rmse:4.14301\tval-rmse:12.1418\ttrain-testme:0.272062\tval-testme:0.483805\n",
      "Stopping. Best iteration:\n",
      "[18]\ttrain-rmse:5.01988\tval-rmse:11.8921\ttrain-testme:0.381139\tval-testme:0.482776\n",
      "\n",
      "feature importance [('avg_c', 326), ('hour', 183), ('weekday', 157), ('avg_l', 100), ('avg_f', 56), ('市场', 36), ('c_has_ex', 36), ('c_has_link', 32), ('电脑', 28), ('需要', 23), ('c_has_at', 22), ('大家', 20), ('c_has_topic', 16), ('主要', 14), ('这里', 13), ('c_has_it', 12), ('软件', 11), ('服务', 11), ('或者', 11), ('现在', 10), ('朋友', 10), ('c_has_share', 9), ('这种', 9), ('有人', 9), ('原因', 8), ('一下', 8), ('不要', 8), ('时间', 7), ('面试', 7), ('小伙', 7), ('笔记', 5), ('设计', 4), ('行业', 4), ('最新', 3), ('评论', 3), ('c_has_video', 2), ('开发者', 2), ('真正', 1), ('c_has_ads', 1), ('加入', 1), ('品牌', 1), ('广告', 1)]\n",
      "[14:55:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\ttrain-rmse:30.103\tval-rmse:35.4137\ttrain-testme:0.594788\tval-testme:0.511409\n",
      "Multiple eval metrics have been passed: 'val-testme' will be used for early stopping.\n",
      "\n",
      "Will train until val-testme hasn't improved in 10 rounds.\n",
      "[1]\ttrain-rmse:29.8521\tval-rmse:35.4025\ttrain-testme:0.56116\tval-testme:0.513393\n",
      "[2]\ttrain-rmse:29.0452\tval-rmse:35.4519\ttrain-testme:0.558323\tval-testme:0.512401\n",
      "[3]\ttrain-rmse:28.185\tval-rmse:35.544\ttrain-testme:0.557482\tval-testme:0.514881\n",
      "[4]\ttrain-rmse:27.3524\tval-rmse:35.6666\ttrain-testme:0.549916\tval-testme:0.509921\n",
      "[5]\ttrain-rmse:26.4816\tval-rmse:35.8127\ttrain-testme:0.547919\tval-testme:0.511905\n",
      "[6]\ttrain-rmse:25.654\tval-rmse:35.9878\ttrain-testme:0.546133\tval-testme:0.50744\n",
      "[7]\ttrain-rmse:25.4222\tval-rmse:35.9718\ttrain-testme:0.53657\tval-testme:0.505456\n",
      "[8]\ttrain-rmse:24.7062\tval-rmse:36.1711\ttrain-testme:0.520177\tval-testme:0.503472\n",
      "[9]\ttrain-rmse:23.9341\tval-rmse:36.388\ttrain-testme:0.51177\tval-testme:0.501488\n",
      "[10]\ttrain-rmse:23.245\tval-rmse:36.6078\ttrain-testme:0.50662\tval-testme:0.495536\n",
      "[11]\ttrain-rmse:22.9499\tval-rmse:36.6961\ttrain-testme:0.504309\tval-testme:0.493552\n",
      "[12]\ttrain-rmse:22.3195\tval-rmse:36.9508\ttrain-testme:0.497583\tval-testme:0.489583\n",
      "[13]\ttrain-rmse:21.8049\tval-rmse:36.9209\ttrain-testme:0.495797\tval-testme:0.485119\n",
      "[14]\ttrain-rmse:21.7135\tval-rmse:36.8867\ttrain-testme:0.486864\tval-testme:0.486607\n",
      "[15]\ttrain-rmse:21.1218\tval-rmse:37.1296\ttrain-testme:0.48224\tval-testme:0.483631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]\ttrain-rmse:20.8199\tval-rmse:37.2579\ttrain-testme:0.470681\tval-testme:0.486607\n",
      "[17]\ttrain-rmse:20.7175\tval-rmse:37.2179\ttrain-testme:0.457125\tval-testme:0.484127\n",
      "[18]\ttrain-rmse:20.6213\tval-rmse:37.1746\ttrain-testme:0.443674\tval-testme:0.485119\n",
      "[19]\ttrain-rmse:20.1237\tval-rmse:37.4385\ttrain-testme:0.431379\tval-testme:0.488095\n",
      "[20]\ttrain-rmse:19.6186\tval-rmse:37.7455\ttrain-testme:0.41467\tval-testme:0.488095\n",
      "[21]\ttrain-rmse:19.6031\tval-rmse:37.7056\ttrain-testme:0.406894\tval-testme:0.486607\n",
      "[22]\ttrain-rmse:19.0869\tval-rmse:37.9837\ttrain-testme:0.393232\tval-testme:0.487599\n",
      "[23]\ttrain-rmse:19.0307\tval-rmse:37.9332\ttrain-testme:0.381883\tval-testme:0.479663\n",
      "[24]\ttrain-rmse:18.5831\tval-rmse:38.2128\ttrain-testme:0.375158\tval-testme:0.479663\n",
      "[25]\ttrain-rmse:18.1105\tval-rmse:38.4903\ttrain-testme:0.364439\tval-testme:0.479663\n",
      "[26]\ttrain-rmse:17.5909\tval-rmse:38.825\ttrain-testme:0.355612\tval-testme:0.479663\n",
      "[27]\ttrain-rmse:17.6616\tval-rmse:38.7662\ttrain-testme:0.346574\tval-testme:0.475198\n",
      "[28]\ttrain-rmse:17.258\tval-rmse:39.1074\ttrain-testme:0.33575\tval-testme:0.475198\n",
      "[29]\ttrain-rmse:17.1466\tval-rmse:39.1926\ttrain-testme:0.32871\tval-testme:0.475198\n",
      "[30]\ttrain-rmse:16.8014\tval-rmse:39.5389\ttrain-testme:0.324611\tval-testme:0.477679\n",
      "[31]\ttrain-rmse:16.3837\tval-rmse:39.8882\ttrain-testme:0.315364\tval-testme:0.481647\n",
      "[32]\ttrain-rmse:16.3531\tval-rmse:39.8274\ttrain-testme:0.298129\tval-testme:0.481647\n",
      "[33]\ttrain-rmse:15.9449\tval-rmse:40.1791\ttrain-testme:0.289723\tval-testme:0.481647\n",
      "[34]\ttrain-rmse:15.5554\tval-rmse:40.5328\ttrain-testme:0.28058\tval-testme:0.475198\n",
      "[35]\ttrain-rmse:15.1699\tval-rmse:40.8863\ttrain-testme:0.279739\tval-testme:0.477183\n",
      "[36]\ttrain-rmse:14.7994\tval-rmse:41.2395\ttrain-testme:0.264607\tval-testme:0.479167\n",
      "[37]\ttrain-rmse:14.4876\tval-rmse:41.5922\ttrain-testme:0.268495\tval-testme:0.479167\n",
      "Stopping. Best iteration:\n",
      "[27]\ttrain-rmse:17.6616\tval-rmse:38.7662\ttrain-testme:0.346574\tval-testme:0.475198\n",
      "\n",
      "feature importance [('avg_l', 473), ('hour', 298), ('weekday', 189), ('avg_f', 69), ('avg_c', 55), ('c_has_ex', 40), ('c_has_link', 30), ('c_has_at', 29), ('这里', 25), ('大家', 24), ('起来', 20), ('如何', 17), ('c_has_it', 16), ('分享', 15), ('需要', 15), ('一下', 14), ('c_has_share', 14), ('c_has_video', 12), ('设计', 10), ('c_has_topic', 10), ('c_has_ads', 7), ('方法', 6), ('软件', 4), ('评论', 2), ('时间', 2), ('小伙', 1)]\n"
     ]
    }
   ],
   "source": [
    "# 生成新模型\n",
    "def calc_dic(train, val, dst, dic):\n",
    "    train_new = train.copy()\n",
    "    for key in dic.keys():\n",
    "        #print(key)\n",
    "        train_new[key] = train['content'].str.contains(key).apply(lambda x: 1 if x else 0)\n",
    "    val_new = val.copy()\n",
    "    for key in dic.keys():\n",
    "        val_new[key] = val['content'].str.contains(key).apply(lambda x: 1 if x else 0)\n",
    "    features = ['weekday', 'hour',\n",
    "           'c_has_link', 'c_has_at', 'c_has_ex', 'c_has_video', 'c_has_ads',\n",
    "           'c_has_share', 'c_has_it', 'avg_l', 'avg_c', 'avg_f', 'c_has_topic']\n",
    "    features_new = features + list(dic.keys())\n",
    "    model = calc(train_new, val_new, features_new, dst, params, testme_f)\n",
    "    return model\n",
    "\n",
    "model_f = calc_dic(train, val, 'f', dic_key_f)\n",
    "model_c = calc_dic(train, val, 'c', dic_key_c)\n",
    "model_l = calc_dic(train, val, 'l', dic_key_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存模型\n",
    "dic = {}\n",
    "dic['model_f'] = model_f\n",
    "dic['model_c'] = model_c\n",
    "dic['model_l'] = model_l\n",
    "dic['dic_key_f'] = dic_key_f\n",
    "dic['dic_key_c'] = dic_key_c\n",
    "dic['dic_key_l'] = dic_key_l\n",
    "dic['user_data_2'] = user_data_2\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(dic, 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28978036754818465\n",
      "(177923, 3)\n",
      "                                uid                               mid     ss\n",
      "0  c01014739c046cd31d6f1b4fb71b440f  0cd5ef13eb11ed0070f7625b14136ec9  0,0,0\n",
      "1  fa5aed172c062c61e196eac61038a03b  7cce78a4ad39a91ec1f595bcc7fb5eba  0,0,0\n",
      "2  77fc723c196a45203e70f4d359c96946  a3494d8cf475a92739a2ffd421640ddf  5,3,4\n",
      "3  e4097b07f34366399b623b94f174f60c  6b89aea5aa7af093dde0894156c49dd3  0,0,0\n",
      "4  d43f7557c303b84070b13aa4eeeb21d3  0bdeff19392e15737775abab46dc5437  0,0,0\n"
     ]
    }
   ],
   "source": [
    "def do_pred(model, val, dic):\n",
    "    val_new = val.copy()\n",
    "    for key in dic.keys():\n",
    "        val_new[key] = val['content'].str.contains(key).apply(lambda x: 1 if x else 0)\n",
    "    features = ['weekday', 'hour',\n",
    "           'c_has_link', 'c_has_at', 'c_has_ex', 'c_has_video', 'c_has_ads',\n",
    "           'c_has_share', 'c_has_it', 'avg_l', 'avg_c', 'avg_f', 'c_has_topic']\n",
    "    features_new = features + list(dic.keys())\n",
    "    tmp = val_new[features_new]\n",
    "    dtest = xgb.DMatrix(tmp)\n",
    "    out = model.predict(dtest)\n",
    "    out = pd.Series(out).apply(lambda x:int(x))\n",
    "    return out\n",
    "\n",
    "def do_pred_all(df):\n",
    "    out = df.copy()\n",
    "    out['f'] = do_pred(model_f, df, dic_key_f)\n",
    "    out['l'] = do_pred(model_l, df, dic_key_l)\n",
    "    out['c'] = do_pred(model_c, df, dic_key_c)\n",
    "    return out\n",
    "\n",
    "# 对验证集预测\n",
    "out = do_pred_all(val)\n",
    "print(tools.do_score(val, out))\n",
    "\n",
    "# 预测并生成提交数据\n",
    "test = pd.read_csv('data/weibo_predict_data.txt',sep='\\t',header=None)\n",
    "test = tools.prepare(test)\n",
    "test = tools.add_features(test)\n",
    "test = pd.merge(test, user_data_2, on='uid', how='left')\n",
    "test = test.fillna(0)\n",
    "out = do_pred_all(test)\n",
    "out['ss'] = out['f'].astype(str) + \",\" + out['c'].astype(str) + ',' + out['l'].astype(str)\n",
    "out = out[['uid','mid','ss']]\n",
    "print(out.shape)\n",
    "print(out.head())\n",
    "out.to_csv(\"result_190624.txt\", index=False, header=None, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
